{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating Siamese GNNs on Synthetic Graph Edit Distance Tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize and load model\n",
    "\n",
    "We first load a particular checkpoint of interest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-06-13T17:10:53.558462Z",
     "end_time": "2024-06-13T17:10:53.613912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GraphMatchingNetwork, GraphConvolutionNetwork\n",
    "import torch\n",
    "\n",
    "# Load checkpoint (full)\n",
    "# filename = f'./checkpoints/gcn_frosty-tree-7.pth.tar'\n",
    "# filename = f'./checkpoints/gmn_glad-bird-6.pth.tar'\n",
    "# filename = f'./checkpoints/gmn_rose-durian-8.pth.tar'\n",
    "# filename = f'./checkpoints/gcn_gentle-universe-26.pth.tar'\n",
    "filename = f'./checkpoints/gmn_ancient-wildflower-24.pth.tar'\n",
    "checkpoint = torch.load(filename, map_location=lambda storage,\n",
    "                        loc: storage.cuda() if torch.cuda.is_available() else storage.cpu())\n",
    "\n",
    "# Retrieve state dict\n",
    "state_dict = checkpoint['state_dict']\n",
    "cfg = checkpoint['config']\n",
    "\n",
    "# Initialize model\n",
    "if cfg.model.name == 'gmn':\n",
    "    model = GraphMatchingNetwork(cfg)\n",
    "elif cfg.model.name == 'gcn':\n",
    "    model = GraphConvolutionNetwork(cfg)\n",
    "else: raise ValueError(\"Model should be either GMN or GCN\")\n",
    "\n",
    "# Load state dict\n",
    "model.load_state_dict(state_dict)  # should output \"<All keys matched successfully>\"\n",
    "\n",
    "# from omegaconf import OmegaConf\n",
    "#\n",
    "# print(OmegaConf.create(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed Triplet Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from utils import load_pickle\n",
    "\n",
    "# Fixed dataset settings\n",
    "num_nodes = 10\n",
    "kp = 1\n",
    "kn = 2\n",
    "pe = 0.2\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_pickle(f\"./data/FixedDatasetGED_nodes={num_nodes}_kp={kp}_kn={kn}_pe={pe}.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-04T18:15:56.572065Z",
     "end_time": "2024-06-04T18:15:56.928785Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Triplet accuracy\n",
    "\n",
    "Here we compute the triplet accuracy. </br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aae13cb925374032af1e8c2c8e54f207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance (nodes=8 kp=1 kn=2 pe=0.2):\n",
      "\tAccuracy:\t1.0\n",
      "\tLosses:\t\t0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import reshape_and_split_tensors\n",
    "from loss import triplet_loss\n",
    "from metrics import euclidean_distance\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set model to eval model\n",
    "model.eval()\n",
    "\n",
    "for num_nodes in [8]:\n",
    "\n",
    "    # Fixed dataset settings\n",
    "    kp = 1\n",
    "    kn = 2\n",
    "    pe = 0.2\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_pickle(f\"./data/FixedDatasetGED_nodes={num_nodes}_kp={kp}_kn={kn}_pe={pe}.pickle\")\n",
    "    dataset = dataset[:100]\n",
    "\n",
    "    # Loop through data\n",
    "    rel_distances = []\n",
    "    losses = []\n",
    "    for triplet in tqdm(dataset, total=len(dataset)):\n",
    "\n",
    "        # Prepare the data\n",
    "        edge_index = triplet['edge_index']  # edge index\n",
    "        node_feats = torch.ones(triplet.num_nodes, cfg.model.node_dim)  # node features to all-ones\n",
    "        edge_feats = torch.ones(triplet.num_edges, cfg.model.edge_dim)  # edge features to all-ones\n",
    "        batch_id = triplet['order']\n",
    "\n",
    "        # Feedforward\n",
    "        _, graph_feats = model(edge_index, x1=node_feats, x2=None, edge_feats=edge_feats, batch=batch_id)\n",
    "        graph_feats = reshape_and_split_tensors(graph_feats, 4)\n",
    "\n",
    "        # Get accuracy measure\n",
    "        rel_distances.append(euclidean_distance(graph_feats[0], graph_feats[1]) \\\n",
    "                   - euclidean_distance(graph_feats[2], graph_feats[3]))\n",
    "\n",
    "        # Get loss\n",
    "        losses.append(triplet_loss(*graph_feats, cfg).detach().numpy())\n",
    "\n",
    "    # print(rel_distances)\n",
    "    losses = np.mean(losses)\n",
    "    corrects = torch.sum(torch.tensor(rel_distances) < 0)\n",
    "    accuracy = corrects / len(dataset)\n",
    "\n",
    "    print(f\"Performance (nodes={num_nodes} kp={kp} kn={kn} pe={pe}):\\n\"\n",
    "          f\"\\tAccuracy:\\t{accuracy}\\n\"\n",
    "          f\"\\tLosses:\\t\\t{losses}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-04T20:58:02.787903Z",
     "end_time": "2024-06-04T20:58:17.362778Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Looks weird ?? Why are the scores so off?**\n",
    "\n",
    "We will try it using the other dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15dd1eb7bf6347a294e4d38688f207a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=10\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.76640\n",
      "\tLoss:\t0.56921\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de19581ce7d342c3bfb9bf82299fa493"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=10\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.60560\n",
      "\tLoss:\t1.10243\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60c8d5c77197459f97514544abb65a9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.90520\n",
      "\tLoss:\t0.24722\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "764a76fe6e9348f8a03df26de6efecac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.74880\n",
      "\tLoss:\t0.60317\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf2e9b110a92411f93d6c78bc261cc9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=50\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.74640\n",
      "\tLoss:\t0.93708\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc9c9a0800949fbb30c326daccab105"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=50\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.64640\n",
      "\tLoss:\t0.93997\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb19125e61654d118105c55e9b495ef8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=1\tkn=2\tpe=0.5\n",
      "Performance:\n",
      "\tAcc:\t0.70600\n",
      "\tLoss:\t0.75921\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e71207abad54d79ae3bb52ebb68dfce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=[10, 20]\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=2\tkn=3\tpe=0.5\n",
      "Performance:\n",
      "\tAcc:\t0.59760\n",
      "\tLoss:\t0.88581\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d060430402248bf8c20a198bd7e5624"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\caspervanengel\\AppData\\Local\\Temp\\ipykernel_12956\\1906423538.py\", line 66, in <module>\n",
      "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\tqdm\\notebook.py\", line 254, in __iter__\n",
      "    for obj in it:\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\tqdm\\std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"C:\\Users\\caspervanengel\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\data.py\", line 80, in __getitem__\n",
      "    G = from_networkx(G)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch_geometric\\utils\\convert.py\", line 206, in from_networkx\n",
      "    G = nx.convert_node_labels_to_integers(G)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\relabel.py\", line 277, in convert_node_labels_to_integers\n",
      "    H = relabel_nodes(G, mapping)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\relabel.py\", line 122, in relabel_nodes\n",
      "    return _relabel_copy(G, m)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\relabel.py\", line 215, in _relabel_copy\n",
      "    H.add_edges_from(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\classes\\graph.py\", line 1016, in add_edges_from\n",
      "    for e in ebunch_to_add:\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\relabel.py\", line 215, in <genexpr>\n",
      "    H.add_edges_from(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\networkx\\classes\\reportviews.py\", line -1, in __iter__\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from utils import reshape_and_split_tensors\n",
    "from loss import triplet_loss\n",
    "from metrics import euclidean_distance\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from data import TripletDatasetGED\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils import AverageMeter\n",
    "from model import GraphMatchingNetwork, GraphConvolutionNetwork\n",
    "import torch\n",
    "\n",
    "filename = f'./checkpoints/gcn_feasible-wave-29.pth.tar'\n",
    "checkpoint = torch.load(filename, map_location=lambda storage,\n",
    "                        loc: storage.cuda() if torch.cuda.is_available() else storage.cpu())\n",
    "\n",
    "# Retrieve state dict\n",
    "state_dict = checkpoint['state_dict']\n",
    "cfg = checkpoint['config']\n",
    "\n",
    "# Initialize model\n",
    "if cfg.model.name == 'gmn':\n",
    "    model = GraphMatchingNetwork(cfg)\n",
    "elif cfg.model.name == 'gcn':\n",
    "    model = GraphConvolutionNetwork(cfg)\n",
    "else: raise ValueError(\"Model should be either GMN or GCN\")\n",
    "\n",
    "# Load state dict\n",
    "model.load_state_dict(state_dict)  # should output \"<All keys matched successfully>\"\n",
    "\n",
    "# from omegaconf import OmegaConf\n",
    "#\n",
    "# print(OmegaConf.create(cfg))\n",
    "\n",
    "# Fixed dataset settings\n",
    "for num_nodes, kp, kn, pe in [[10, 1, 2, 0.2],\n",
    "                              [10, 2, 3, 0.2],\n",
    "                              [20, 1, 2, 0.2],\n",
    "                              [20, 2, 3, 0.2],\n",
    "                              [50, 1, 2, 0.2],\n",
    "                              [50, 2, 3, 0.2],\n",
    "                              [20, 1, 2, 0.5],\n",
    "                              [20, 2, 3, 0.5],\n",
    "                              [50, 1, 2, 0.5],\n",
    "                              [50, 2, 3, 0.5]]:\n",
    "\n",
    "    # Dataloader and size\n",
    "    N = 50000\n",
    "    bs = 20\n",
    "    size = int(np.ceil(N / bs))\n",
    "\n",
    "    # Initialize dataset and loader\n",
    "    dataset = TripletDatasetGED(size=size, num_nodes=num_nodes,\n",
    "                                kp=kp, kn=kn, pe=pe,\n",
    "                                permute=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Loop through data\n",
    "        val_loss = AverageMeter()\n",
    "        val_accs = AverageMeter()\n",
    "\n",
    "        for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "\n",
    "            # Prepare the data\n",
    "            edge_index = batch['edge_index']  # edge index\n",
    "            node_feats = torch.ones(batch.num_nodes, cfg.model.node_dim)  # node features to all-ones\n",
    "            edge_feats = torch.ones(batch.num_edges, cfg.model.edge_dim)  # edge features to all-ones\n",
    "            batch_id = batch['order'] + 4 * batch['batch']\n",
    "\n",
    "            # Feedforward\n",
    "            _, graph_feats = model(edge_index, x1=node_feats, x2=None, edge_feats=edge_feats, batch=batch_id)\n",
    "            graph_feats = reshape_and_split_tensors(graph_feats, 4)\n",
    "\n",
    "            # Compute and append loss\n",
    "            losses = triplet_loss(*graph_feats, cfg)\n",
    "\n",
    "            loss = losses.mean()\n",
    "            val_loss.update(loss.item())\n",
    "\n",
    "            # Performance (accuracy)\n",
    "            rel_distance = euclidean_distance(graph_feats[0], graph_feats[1]) \\\n",
    "                       - euclidean_distance(graph_feats[2], graph_feats[3])\n",
    "            corrects = torch.sum(rel_distance < 0)\n",
    "            val_accs.update(corrects.item() / bs)\n",
    "\n",
    "        print(f\"Train:\\t----- \"\n",
    "              f\"N={cfg.data.num_nodes}\"\n",
    "              f\"\\tkp={cfg.data.kp}\"\n",
    "              f\"\\tkn={cfg.data.kn}\"\n",
    "              f\"\\tpe={cfg.data.pe}\")\n",
    "        print(f\"Eval:\\t----- \"\n",
    "              f\"N={num_nodes}\"\n",
    "              f\"\\tkp={kp}\"\n",
    "              f\"\\tkn={kn}\"\n",
    "              f\"\\tpe={pe}\")\n",
    "        print(f\"Performance:\\n\"\n",
    "              f\"\\tAcc:\\t{val_accs.avg:.5f}\\n\"\n",
    "              f\"\\tLoss:\\t{val_loss.avg:.5f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-18T15:59:56.565137Z",
     "end_time": "2024-06-18T16:07:23.216845Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
