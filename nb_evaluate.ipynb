{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating Siamese GNNs on Synthetic Graph Edit Distance Tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize and load model\n",
    "\n",
    "We first load a particular checkpoint of interest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-06-13T17:10:53.558462Z",
     "end_time": "2024-06-13T17:10:53.613912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GraphMatchingNetwork, GraphConvolutionNetwork\n",
    "import torch\n",
    "\n",
    "# Load checkpoint (full)\n",
    "# filename = f'./checkpoints/gcn_frosty-tree-7.pth.tar'\n",
    "# filename = f'./checkpoints/gmn_glad-bird-6.pth.tar'\n",
    "# filename = f'./checkpoints/gmn_rose-durian-8.pth.tar'\n",
    "# filename = f'./checkpoints/gcn_gentle-universe-26.pth.tar'\n",
    "filename = f'./checkpoints/gmn_ancient-wildflower-24.pth.tar'\n",
    "checkpoint = torch.load(filename, map_location=lambda storage,\n",
    "                        loc: storage.cuda() if torch.cuda.is_available() else storage.cpu())\n",
    "\n",
    "# Retrieve state dict\n",
    "state_dict = checkpoint['state_dict']\n",
    "cfg = checkpoint['config']\n",
    "\n",
    "# Initialize model\n",
    "if cfg.model.name == 'gmn':\n",
    "    model = GraphMatchingNetwork(cfg)\n",
    "elif cfg.model.name == 'gcn':\n",
    "    model = GraphConvolutionNetwork(cfg)\n",
    "else: raise ValueError(\"Model should be either GMN or GCN\")\n",
    "\n",
    "# Load state dict\n",
    "model.load_state_dict(state_dict)  # should output \"<All keys matched successfully>\"\n",
    "\n",
    "# from omegaconf import OmegaConf\n",
    "#\n",
    "# print(OmegaConf.create(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed Triplet Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from utils import load_pickle\n",
    "\n",
    "# Fixed dataset settings\n",
    "num_nodes = 10\n",
    "kp = 1\n",
    "kn = 2\n",
    "pe = 0.2\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_pickle(f\"./data/FixedDatasetGED_nodes={num_nodes}_kp={kp}_kn={kn}_pe={pe}.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-04T18:15:56.572065Z",
     "end_time": "2024-06-04T18:15:56.928785Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Triplet accuracy\n",
    "\n",
    "Here we compute the triplet accuracy. </br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aae13cb925374032af1e8c2c8e54f207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance (nodes=8 kp=1 kn=2 pe=0.2):\n",
      "\tAccuracy:\t1.0\n",
      "\tLosses:\t\t0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import reshape_and_split_tensors\n",
    "from loss import triplet_loss\n",
    "from metrics import euclidean_distance\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set model to eval model\n",
    "model.eval()\n",
    "\n",
    "for num_nodes in [8]:\n",
    "\n",
    "    # Fixed dataset settings\n",
    "    kp = 1\n",
    "    kn = 2\n",
    "    pe = 0.2\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_pickle(f\"./data/FixedDatasetGED_nodes={num_nodes}_kp={kp}_kn={kn}_pe={pe}.pickle\")\n",
    "    dataset = dataset[:100]\n",
    "\n",
    "    # Loop through data\n",
    "    rel_distances = []\n",
    "    losses = []\n",
    "    for triplet in tqdm(dataset, total=len(dataset)):\n",
    "\n",
    "        # Prepare the data\n",
    "        edge_index = triplet['edge_index']  # edge index\n",
    "        node_feats = torch.ones(triplet.num_nodes, cfg.model.node_dim)  # node features to all-ones\n",
    "        edge_feats = torch.ones(triplet.num_edges, cfg.model.edge_dim)  # edge features to all-ones\n",
    "        batch_id = triplet['order']\n",
    "\n",
    "        # Feedforward\n",
    "        _, graph_feats = model(edge_index, x1=node_feats, x2=None, edge_feats=edge_feats, batch=batch_id)\n",
    "        graph_feats = reshape_and_split_tensors(graph_feats, 4)\n",
    "\n",
    "        # Get accuracy measure\n",
    "        rel_distances.append(euclidean_distance(graph_feats[0], graph_feats[1]) \\\n",
    "                   - euclidean_distance(graph_feats[2], graph_feats[3]))\n",
    "\n",
    "        # Get loss\n",
    "        losses.append(triplet_loss(*graph_feats, cfg).detach().numpy())\n",
    "\n",
    "    # print(rel_distances)\n",
    "    losses = np.mean(losses)\n",
    "    corrects = torch.sum(torch.tensor(rel_distances) < 0)\n",
    "    accuracy = corrects / len(dataset)\n",
    "\n",
    "    print(f\"Performance (nodes={num_nodes} kp={kp} kn={kn} pe={pe}):\\n\"\n",
    "          f\"\\tAccuracy:\\t{accuracy}\\n\"\n",
    "          f\"\\tLosses:\\t\\t{losses}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-04T20:58:02.787903Z",
     "end_time": "2024-06-04T20:58:17.362778Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Looks weird ?? Why are the scores so off?**\n",
    "\n",
    "We will try it using the other dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab86e5cf07324487ba971cf18dca7b42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=10\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.67308\n",
      "\tLoss:\t1.61258\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10e56105c0364f93b5d9b78a26fb1a40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=10\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.57308\n",
      "\tLoss:\t3.37559\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6947a0c694e4c4e80dc3a8d1c9eb29d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.89615\n",
      "\tLoss:\t0.21050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "300d8f1fdc14463ba69b42231fa2e799"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=20\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.73077\n",
      "\tLoss:\t0.85011\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b1d972c3f654cc9b817059b1e221774"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=50\tkp=1\tkn=2\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.62308\n",
      "\tLoss:\t1.00589\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e214fafc2f4d0db2d923099908c057"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t----- N=20\tkp=1\tkn=2\tpe=0.2\n",
      "Eval:\t----- N=50\tkp=2\tkn=3\tpe=0.2\n",
      "Performance:\n",
      "\tAcc:\t0.54231\n",
      "\tLoss:\t1.75500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c2270779248447ab6b2f4df4cf217c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 51\u001B[0m\n\u001B[0;32m     48\u001B[0m batch_id \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124morder\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m*\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Feedforward\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m _, graph_feats \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode_feats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_feats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_feats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m graph_feats \u001B[38;5;241m=\u001B[39m reshape_and_split_tensors(graph_feats, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Compute and append loss\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\model.py:300\u001B[0m, in \u001B[0;36mGraphConvolutionNetwork.forward\u001B[1;34m(self, edge_index, x1, x2, edge_feats, batch)\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;66;03m# compute node embeddings (graph matching convolutional layers)\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers):\n\u001B[1;32m--> 300\u001B[0m     node_feats \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_layers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_feats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_feats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;66;03m# compute graph-level embeddings (graph aggregation mean)\u001B[39;00m\n\u001B[0;32m    304\u001B[0m graph_feats \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregator(node_feats, batch)\n",
      "File \u001B[1;32mc:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\model.py:165\u001B[0m, in \u001B[0;36mGMNConv.forward\u001B[1;34m(self, edge_index, x, edge_attr, batch)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, edge_index, x, edge_attr, batch):\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# x_transformed = self.lin_node(x)\u001B[39;00m\n\u001B[1;32m--> 165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_x\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\caspervanengel\\Anaconda3\\envs\\pytorch-geom\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:462\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    459\u001B[0m         out \u001B[38;5;241m=\u001B[39m res\n\u001B[0;32m    461\u001B[0m update_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minspector\u001B[38;5;241m.\u001B[39mdistribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mupdate\u001B[39m\u001B[38;5;124m'\u001B[39m, coll_dict)\n\u001B[1;32m--> 462\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mupdate_kwargs)\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decomposed_layers \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    465\u001B[0m     decomp_out\u001B[38;5;241m.\u001B[39mappend(out)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\model.py:173\u001B[0m, in \u001B[0;36mGMNConv.update\u001B[1;34m(self, aggr_out, original_x, batch)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, aggr_out, original_x, batch):\n\u001B[1;32m--> 173\u001B[0m     cross_graph_attention \u001B[38;5;241m=\u001B[39m \u001B[43mbatch_pair_cross_attention\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m     attention_input \u001B[38;5;241m=\u001B[39m original_x \u001B[38;5;241m-\u001B[39m cross_graph_attention\n\u001B[0;32m    175\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([aggr_out, attention_input], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\model.py:68\u001B[0m, in \u001B[0;36mbatch_pair_cross_attention\u001B[1;34m(feats, batch, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m x \u001B[38;5;241m=\u001B[39m block_feats[i]\n\u001B[0;32m     67\u001B[0m y \u001B[38;5;241m=\u001B[39m block_feats[i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 68\u001B[0m attention_x, attention_y \u001B[38;5;241m=\u001B[39m cross_attention(x, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     69\u001B[0m outs\u001B[38;5;241m.\u001B[39mappend(attention_x)\n\u001B[0;32m     70\u001B[0m outs\u001B[38;5;241m.\u001B[39mappend(attention_y)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\PHD\\0_code\\recent\\gmn-pyg\\model.py:47\u001B[0m, in \u001B[0;36mcross_attention\u001B[1;34m(x, y, sim)\u001B[0m\n\u001B[0;32m     45\u001B[0m a_x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(a, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# i->j\u001B[39;00m\n\u001B[0;32m     46\u001B[0m a_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(a, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# j->i\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m attention_x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m attention_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmm(torch\u001B[38;5;241m.\u001B[39mtranspose(a_y, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m), x)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m attention_x, attention_y\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from utils import reshape_and_split_tensors\n",
    "from loss import triplet_loss\n",
    "from metrics import euclidean_distance\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from data import TripletDatasetGED\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils import AverageMeter\n",
    "\n",
    "# Fixed dataset settings\n",
    "for num_nodes, kp, kn, pe in [[10, 1, 2, 0.2],\n",
    "                              [10, 2, 3, 0.2],\n",
    "                              [20, 1, 2, 0.2],\n",
    "                              [20, 2, 3, 0.2],\n",
    "                              [50, 1, 2, 0.2],\n",
    "                              [50, 2, 3, 0.2],\n",
    "                              [20, 1, 2, 0.5],\n",
    "                              [20, 2, 3, 0.5],\n",
    "                              [50, 1, 2, 0.5],\n",
    "                              [50, 2, 3, 0.5]]:\n",
    "\n",
    "    # Dataloader and size\n",
    "    N = 5000\n",
    "    bs = 20\n",
    "    size = int(np.ceil(N / bs))\n",
    "\n",
    "    # Initialize dataset and loader\n",
    "    dataset = TripletDatasetGED(size=size, num_nodes=num_nodes,\n",
    "                                kp=kp, kn=kn, pe=pe,\n",
    "                                permute=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Loop through data\n",
    "        val_loss = AverageMeter()\n",
    "        val_accs = AverageMeter()\n",
    "\n",
    "        for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "\n",
    "            # Prepare the data\n",
    "            edge_index = batch['edge_index']  # edge index\n",
    "            node_feats = torch.ones(batch.num_nodes, cfg.model.node_dim)  # node features to all-ones\n",
    "            edge_feats = torch.ones(batch.num_edges, cfg.model.edge_dim)  # edge features to all-ones\n",
    "            batch_id = batch['order'] + 4 * batch['batch']\n",
    "\n",
    "            # Feedforward\n",
    "            _, graph_feats = model(edge_index, x1=node_feats, x2=None, edge_feats=edge_feats, batch=batch_id)\n",
    "            graph_feats = reshape_and_split_tensors(graph_feats, 4)\n",
    "\n",
    "            # Compute and append loss\n",
    "            losses = triplet_loss(*graph_feats, cfg)\n",
    "\n",
    "            loss = losses.mean()\n",
    "            val_loss.update(loss.item())\n",
    "\n",
    "            # Performance (accuracy)\n",
    "            rel_distance = euclidean_distance(graph_feats[0], graph_feats[1]) \\\n",
    "                       - euclidean_distance(graph_feats[2], graph_feats[3])\n",
    "            corrects = torch.sum(rel_distance < 0)\n",
    "            val_accs.update(corrects.item() / bs)\n",
    "\n",
    "        print(f\"Train:\\t----- \"\n",
    "              f\"N={cfg.data.num_nodes}\"\n",
    "              f\"\\tkp={cfg.data.kp}\"\n",
    "              f\"\\tkn={cfg.data.kn}\"\n",
    "              f\"\\tpe={cfg.data.pe}\")\n",
    "        print(f\"Eval:\\t----- \"\n",
    "              f\"N={num_nodes}\"\n",
    "              f\"\\tkp={kp}\"\n",
    "              f\"\\tkn={kn}\"\n",
    "              f\"\\tpe={pe}\")\n",
    "        print(f\"Performance:\\n\"\n",
    "              f\"\\tAcc:\\t{val_accs.avg:.5f}\\n\"\n",
    "              f\"\\tLoss:\\t{val_loss.avg:.5f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T20:06:56.042945Z",
     "end_time": "2024-06-05T20:28:33.858034Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
